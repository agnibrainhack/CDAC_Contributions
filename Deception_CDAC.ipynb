{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deception_CDAC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Tl3_Navkimot",
        "colab_type": "code",
        "outputId": "fe84d144-4b47-4bed-b410-b2ac9e266562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deceptive-opinion.csv\t\t   drive     sample_data\n",
            "deceptive-opinion-spam-corpus.zip  model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9zdQkpNQh955",
        "colab_type": "code",
        "outputId": "6f748168-097c-4825-eed0-09268ba7fc2b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-01cff643-ae30-4a9c-b379-24bb17454cbd\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-01cff643-ae30-4a9c-b379-24bb17454cbd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving deceptive-opinion-spam-corpus.zip to deceptive-opinion-spam-corpus.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wTfLq-sXuaeO",
        "colab_type": "code",
        "outputId": "0a6f2282-506d-42a6-e1ac-08438ee29866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RB9Zkfk8upfT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp drive/My\\ Drive/deceptive-opinion-spam-corpus.zip .\n",
        "# !cp drive/My\\ Drive/glove.6B.200d.txt ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UBedFPcGnxrn",
        "colab_type": "code",
        "outputId": "c069f366-629d-4337-99ab-ec1f4aba3868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip deceptive-opinion-spam-corpus.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  deceptive-opinion-spam-corpus.zip\n",
            "  inflating: deceptive-opinion.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7Rw8CZFxGPh-",
        "colab_type": "code",
        "outputId": "319b3754-062b-457a-e4ac-52c3a4e1b984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install --quiet sentencepiece"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    0% |▎                               | 10kB 20.2MB/s eta 0:00:01\r\u001b[K    1% |▋                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K    2% |█                               | 30kB 3.2MB/s eta 0:00:01\r\u001b[K    3% |█▎                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K    4% |█▋                              | 51kB 2.6MB/s eta 0:00:01\r\u001b[K    5% |██                              | 61kB 3.0MB/s eta 0:00:01\r\u001b[K    6% |██▏                             | 71kB 3.5MB/s eta 0:00:01\r\u001b[K    7% |██▌                             | 81kB 4.0MB/s eta 0:00:01\r\u001b[K    8% |██▉                             | 92kB 4.4MB/s eta 0:00:01\r\u001b[K    9% |███▏                            | 102kB 3.4MB/s eta 0:00:01\r\u001b[K    10% |███▌                            | 112kB 3.4MB/s eta 0:00:01\r\u001b[K    11% |███▉                            | 122kB 4.9MB/s eta 0:00:01\r\u001b[K    12% |████                            | 133kB 4.8MB/s eta 0:00:01\r\u001b[K    13% |████▍                           | 143kB 8.9MB/s eta 0:00:01\r\u001b[K    14% |████▊                           | 153kB 9.0MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 163kB 9.0MB/s eta 0:00:01\r\u001b[K    16% |█████▍                          | 174kB 9.0MB/s eta 0:00:01\r\u001b[K    17% |█████▊                          | 184kB 9.0MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 194kB 9.0MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 204kB 40.8MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 215kB 10.2MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 225kB 10.2MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 235kB 10.5MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 245kB 10.5MB/s eta 0:00:01\r\u001b[K    24% |███████▉                        | 256kB 10.6MB/s eta 0:00:01\r\u001b[K    25% |████████▏                       | 266kB 10.5MB/s eta 0:00:01\r\u001b[K    26% |████████▌                       | 276kB 10.6MB/s eta 0:00:01\r\u001b[K    27% |████████▉                       | 286kB 10.7MB/s eta 0:00:01\r\u001b[K    28% |█████████▏                      | 296kB 10.6MB/s eta 0:00:01\r\u001b[K    29% |█████████▌                      | 307kB 10.9MB/s eta 0:00:01\r\u001b[K    30% |█████████▊                      | 317kB 56.7MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 327kB 57.7MB/s eta 0:00:01\r\u001b[K    32% |██████████▍                     | 337kB 59.1MB/s eta 0:00:01\r\u001b[K    33% |██████████▊                     | 348kB 50.3MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 358kB 50.4MB/s eta 0:00:01\r\u001b[K    35% |███████████▍                    | 368kB 56.3MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 378kB 56.0MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 389kB 55.1MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 399kB 11.6MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 409kB 11.4MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 419kB 11.4MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 430kB 11.4MB/s eta 0:00:01\r\u001b[K    42% |█████████████▌                  | 440kB 11.3MB/s eta 0:00:01\r\u001b[K    43% |█████████████▉                  | 450kB 11.5MB/s eta 0:00:01\r\u001b[K    44% |██████████████▏                 | 460kB 11.4MB/s eta 0:00:01\r\u001b[K    45% |██████████████▌                 | 471kB 11.4MB/s eta 0:00:01\r\u001b[K    46% |██████████████▉                 | 481kB 11.4MB/s eta 0:00:01\r\u001b[K    47% |███████████████▏                | 491kB 11.5MB/s eta 0:00:01\r\u001b[K    48% |███████████████▍                | 501kB 52.4MB/s eta 0:00:01\r\u001b[K    49% |███████████████▊                | 512kB 47.1MB/s eta 0:00:01\r\u001b[K    50% |████████████████                | 522kB 46.7MB/s eta 0:00:01\r\u001b[K    51% |████████████████▍               | 532kB 48.0MB/s eta 0:00:01\r\u001b[K    52% |████████████████▊               | 542kB 49.5MB/s eta 0:00:01\r\u001b[K    53% |█████████████████               | 552kB 55.8MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▎              | 563kB 57.6MB/s eta 0:00:01\r\u001b[K    55% |█████████████████▋              | 573kB 57.0MB/s eta 0:00:01\r\u001b[K    56% |██████████████████              | 583kB 56.7MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 593kB 56.8MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 604kB 57.5MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 614kB 70.2MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▏            | 624kB 71.4MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▌            | 634kB 67.5MB/s eta 0:00:01\r\u001b[K    62% |███████████████████▉            | 645kB 65.1MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▏           | 655kB 62.7MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▌           | 665kB 50.0MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▉           | 675kB 47.8MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████▏          | 686kB 48.0MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▍          | 696kB 47.0MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▊          | 706kB 46.4MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 716kB 45.4MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▍         | 727kB 45.8MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▊         | 737kB 16.9MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 747kB 16.9MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 757kB 16.9MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 768kB 18.1MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 778kB 18.4MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 788kB 18.3MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 798kB 18.5MB/s eta 0:00:01\r\u001b[K    77% |█████████████████████████       | 808kB 18.5MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 819kB 18.3MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 829kB 18.2MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 839kB 59.3MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 849kB 62.2MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 860kB 57.6MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 870kB 57.2MB/s eta 0:00:01\r\u001b[K    84% |███████████████████████████     | 880kB 56.0MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▍    | 890kB 56.4MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▊    | 901kB 55.2MB/s eta 0:00:01\r\u001b[K    87% |████████████████████████████    | 911kB 56.3MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▍   | 921kB 58.8MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▊   | 931kB 61.0MB/s eta 0:00:01\r\u001b[K    90% |█████████████████████████████   | 942kB 60.9MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▎  | 952kB 60.6MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▋  | 962kB 67.3MB/s eta 0:00:01\r\u001b[K    93% |██████████████████████████████  | 972kB 65.8MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▎ | 983kB 66.9MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▋ | 993kB 67.9MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 1.0MB 70.0MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 1.0MB 69.4MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 1.0MB 68.9MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 1.0MB 65.1MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 1.0MB 18.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pjNBhJsFiqyD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, BatchNormalization, Dropout, Reshape\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "import keras\n",
        "from sklearn.utils import resample\n",
        "\n",
        "from keras.layers import Activation, Conv1D, Conv2D, Bidirectional, GlobalMaxPool1D\n",
        "from keras.layers import Input, Lambda, Dense, Dropout, Convolution2D, MaxPooling2D, Flatten, MaxPooling1D\n",
        "from keras.layers import Bidirectional, Concatenate, Permute, Dot, LSTM, Multiply, Flatten\n",
        "from keras.layers import RepeatVector, Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Sequential, Model\n",
        "from keras import backend as K\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import load_model\n",
        "from keras import optimizers as opt\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, Callback\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.max_columns = 15\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns\n",
        "import tqdm\n",
        "# import sentencepiece as spm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vHDLQG98i8IN",
        "colab_type": "code",
        "outputId": "44082af5-770b-48ee-b881-9703dd386f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('deceptive-opinion.csv')\n",
        "# Keeping only the neccessary columns\n",
        "data = data[['text','deceptive']]\n",
        "data.head(1)\n",
        "data = data.sample(frac=1)\n",
        "data = data.sample(frac=1)\n",
        "data = data.sample(frac=1)\n",
        "\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "\n",
        "\n",
        "data = data.replace(['truthful', 'deceptive'], [1, 0])\n",
        "print(len(data[ data['deceptive'] == 1]))\n",
        "print(len(data[ data['deceptive'] == 0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800\n",
            "800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JmWABuL9Q8XB",
        "colab_type": "code",
        "outputId": "276db1e3-0b8d-4cad-c11d-e3ba6a906012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "cell_type": "code",
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
        "embed = hub.Module(module_url)\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
            "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/3'.\n",
            "INFO:tensorflow:Downloaded https://tfhub.dev/google/universal-sentence-encoder-large/3, Total size: 810.60MB\n",
            "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/3'.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dKV_bvWjmlwK",
        "colab_type": "code",
        "outputId": "5d1cbb48-8f72-4dad-9e8d-d99665293e5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-lite/2\"\n",
        "module = hub.Module(module_url)\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "input_placeholder = tf.sparse_placeholder(tf.int64, shape=[None, None])\n",
        "encodings = module(\n",
        "    inputs=dict(\n",
        "        values=input_placeholder.values,\n",
        "        indices=input_placeholder.indices,\n",
        "        dense_shape=input_placeholder.dense_shape))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    spm_path = sess.run(module(signature=\"spm_path\"))\n",
        "\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load(spm_path)\n",
        "print(\"SentencePiece model loaded at {}.\".format(spm_path))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentencePiece model loaded at b'/tmp/tfhub_modules/539544f0a997d91c327c23285ea00c37588d92cc/assets/universal_encoder_8k_spm.model'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gisY6iFBGgSV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def process_to_IDs_in_sparse_format(sp, sentences):\n",
        "    # An utility method that processes sentences with the sentence piece processor\n",
        "    # 'sp' and returns the results in tf.SparseTensor-similar format:\n",
        "    # (values, indices, dense_shape)\n",
        "    ids = [sp.EncodeAsIds(x) for x in sentences]\n",
        "    max_len = max(len(x) for x in ids)\n",
        "    dense_shape=(len(ids), max_len)\n",
        "    values=[item for sublist in ids for item in sublist]\n",
        "    indices=[[row,col] for row in range(len(ids)) for col in range(len(ids[row]))]\n",
        "    return (values, indices, dense_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZeDOUUevo0sB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sentences_to_indices(X, max_len=512):\n",
        "    \n",
        "    m = X.shape[0]                                   # number of training examples\n",
        "    vector = []\n",
        "    X = X.values\n",
        "#     print(X[0])\n",
        "#     X_indices = np.zeros((m, max_len))\n",
        "    with tf.Session() as session:\n",
        "        for i in tqdm.tqdm(range(m)):                               # loop over training examples\n",
        "            sentences = X[i].split('.')\n",
        "    #             print(sentences)\n",
        "            values, indices, dense_shape = process_to_IDs_in_sparse_format(sp, sentences)\n",
        "\n",
        "            session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "            message_embeddings = session.run(encodings, feed_dict={input_placeholder.values: values,\n",
        "                        input_placeholder.indices: indices,\n",
        "                        input_placeholder.dense_shape: dense_shape})\n",
        "            vector.append(np.array(message_embeddings).tolist())\n",
        "\n",
        "    X_indices = np.array(vector)\n",
        "    X_indices = np.squeeze(X_indices)\n",
        "    return X_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kim6qUgBeHt0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# data=data[:100]\n",
        "# data['text']\n",
        "indices = sentences_to_indices(data['text'])\n",
        "indices = indices.reshape(10, 512, 1)\n",
        "indices.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9qcqNneon0T-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "embeddings_file = \"embeddings-{}.pickle\".format(len(indices))\n",
        "pickle.dump(indices, open(embeddings_file, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k1ilnk-mCjRF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp embeddings-100.pickle drive/My\\ Drive ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I88G3hSPot87",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "indices = pickle.load(open('tweets_embeddings.pickle', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JauRVPMqpLgW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def euclidean_distance(inputs):\n",
        "    assert len(inputs) == 2, \\\n",
        "        'Euclidean distance needs 2 inputs, %d given' % len(inputs)\n",
        "    u, v = inputs\n",
        "    return K.sqrt(K.sum((K.square(u - v)), axis=1, keepdims=True))\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n",
        "\n",
        "def exponent_neg_manhattan_distance(left, right):\n",
        "    ''' Helper function for the similarity estimate of the LSTMs outputs'''\n",
        "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))\n",
        "def UniversalEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)), \n",
        "    \tsignature=\"default\", as_dict=True)[\"default\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4gryrwM2OTpQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class xz():\n",
        "    def __init__(self):\n",
        "        self.x=1;\n",
        "        self.z=0\n",
        "def model_emb(obj, embed_size = 512):\n",
        "    input_text = Input(shape=(1,), dtype=tf.string)\n",
        "#     print(keras.backend.shape(input_text))\n",
        "    \n",
        "    \n",
        "    embedding = Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text)\n",
        "#     flat = Flatten()(embedding)\n",
        "#     layer.output_shape\n",
        "\n",
        "    flat = Reshape((512, obj.x))(embedding)\n",
        "    obj.x = 32\n",
        "    lstm = Bidirectional(LSTM(32, dropout=0.2, recurrent_dropout=0.3))(flat)\n",
        "    dense = Dense(128, activation='relu')(lstm)\n",
        "    \n",
        "    pred = Dense(2, activation='softmax')(dense)\n",
        "    model = Model(inputs=[input_text], outputs=pred)\n",
        "    model.compile(loss='categorical_crossentropy', \n",
        "    optimizer=opt.Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SWOY3IBaV5M0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_cdac(embed_size = 512):\n",
        "    input_text = Input(shape=(1,), dtype=tf.string, name='input1')\n",
        "#     print(keras.backend.shape(input_text))\n",
        "    \n",
        "    \n",
        "    embedding = Lambda(UniversalEmbedding, output_shape=(embed_size,), name='embed1')(input_text)\n",
        "    \n",
        "    dense = Dense(512, activation='relu', name='dense1')(embedding)\n",
        "    dense = Dense(256, activation='relu', name='dense2')(dense)\n",
        "    dense = Dense(256, activation='relu', name='dense3')(dense)\n",
        "#     dense = Dense(64, activation='relu', name='dense3')(dense)\n",
        "#     dense = Dense(24, activation='relu', name='dense4')(dense)\n",
        "    pred = Dense(2, activation='softmax', name='dense5')(dense)\n",
        "    model = Model(inputs=[input_text], outputs=pred)\n",
        "    model.compile(loss='categorical_crossentropy', \n",
        "    optimizer=opt.Adam(lr=0.0001, decay=1e-5), metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bpVhzLcsPyYY",
        "colab_type": "code",
        "outputId": "f9cbeae9-e122-4fdc-9229-94ce1815e735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "cell_type": "code",
      "source": [
        "Y_train = pd.get_dummies(data['deceptive']).values\n",
        "\n",
        "X_train = data['text'].tolist()\n",
        "X_train = np.array(X_train, dtype=object)[:, np.newaxis]\n",
        "# model = load_model('model.h5')\n",
        "# model = model_cdac()\n",
        "# model.load_weights('model.h5')\n",
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    session.run(tf.tables_initializer())\n",
        "    model = model_cdac()\n",
        "    history = model.fit(X_train, \n",
        "            Y_train,\n",
        "            validation_split=0.07,\n",
        "            epochs=13,\n",
        "            batch_size=32)\n",
        "    model.save_weights('./model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1488 samples, validate on 112 samples\n",
            "Epoch 1/13\n",
            "1488/1488 [==============================] - 11s 7ms/step - loss: 0.6782 - acc: 0.6082 - val_loss: 0.6592 - val_acc: 0.6250\n",
            "Epoch 2/13\n",
            "1488/1488 [==============================] - 7s 5ms/step - loss: 0.6256 - acc: 0.7198 - val_loss: 0.5636 - val_acc: 0.8214\n",
            "Epoch 3/13\n",
            "1488/1488 [==============================] - 7s 5ms/step - loss: 0.5403 - acc: 0.7440 - val_loss: 0.4676 - val_acc: 0.7946\n",
            "Epoch 4/13\n",
            "1488/1488 [==============================] - 7s 5ms/step - loss: 0.4826 - acc: 0.7742 - val_loss: 0.4347 - val_acc: 0.8036\n",
            "Epoch 5/13\n",
            "1488/1488 [==============================] - 7s 5ms/step - loss: 0.4497 - acc: 0.7849 - val_loss: 0.4058 - val_acc: 0.8304\n",
            "Epoch 6/13\n",
            "1488/1488 [==============================] - 7s 5ms/step - loss: 0.4221 - acc: 0.8031 - val_loss: 0.4058 - val_acc: 0.8482\n",
            "Epoch 7/13\n",
            "1488/1488 [==============================] - 7s 5ms/step - loss: 0.4022 - acc: 0.8179 - val_loss: 0.3771 - val_acc: 0.8393\n",
            "Epoch 8/13\n",
            "1488/1488 [==============================] - 7s 5ms/step - loss: 0.3798 - acc: 0.8360 - val_loss: 0.4054 - val_acc: 0.8214\n",
            "Epoch 9/13\n",
            "1488/1488 [==============================] - 7s 5ms/step - loss: 0.3756 - acc: 0.8219 - val_loss: 0.3709 - val_acc: 0.8571\n",
            "Epoch 10/13\n",
            "1488/1488 [==============================] - 7s 5ms/step - loss: 0.3512 - acc: 0.8434 - val_loss: 0.3705 - val_acc: 0.8393\n",
            "Epoch 11/13\n",
            "1488/1488 [==============================] - 7s 5ms/step - loss: 0.3219 - acc: 0.8629 - val_loss: 0.3575 - val_acc: 0.8393\n",
            "Epoch 12/13\n",
            "1488/1488 [==============================] - 7s 5ms/step - loss: 0.3009 - acc: 0.8716 - val_loss: 0.3514 - val_acc: 0.8393\n",
            "Epoch 13/13\n",
            "1488/1488 [==============================] - 7s 5ms/step - loss: 0.2776 - acc: 0.8911 - val_loss: 0.3487 - val_acc: 0.8304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tFl-lsPRfru-",
        "colab_type": "code",
        "outputId": "3e82d7ed-9008-4979-d56d-69b94a6531f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "cell_type": "code",
      "source": [
        "new_text = [\"In what year did the titanic sink ?\", \n",
        "            \"What is the highest peak in California ?\", \n",
        "            \"Who invented the light bulb ?\"]\n",
        "\n",
        "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    session.run(tf.tables_initializer())\n",
        "#     model.load_weights('./model.h5')  \n",
        "    predicts = model.evaluate(X_train, Y_train, verbose=1)\n",
        "\n",
        "# categories = df_train.label.cat.categories.tolist()\n",
        "print(predicts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  32/1600 [..............................] - ETA: 7:00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7ff7cc129e10>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
            "    self._session._session, self._handle, status)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
            "    c_api.TF_GetCode(self.status.status))\n",
            "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1600/1600 [==============================] - 15s 10ms/step\n",
            "[0.694139541387558, 0.470625]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jl4flZtE12v8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1eBNJSLRppdn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def model_lstm_dec(vector_size):\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same',\n",
        "                     input_shape=(vector_size, 1)))\n",
        "    model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
        "    model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
        "    model.add(MaxPooling1D(pool_size=3))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(512, dropout=0.2, recurrent_dropout=0.3)))\n",
        "\n",
        "    model.add(Dense(512, activation='sigmoid'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(512, activation='sigmoid'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(512, activation='sigmoid'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt.Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
        "\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p6lmLYqVrjFJ",
        "colab_type": "code",
        "outputId": "b4342f9e-840e-42f3-b912-47ac67eb6634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = model_lstm_dec(512)\n",
        "\n",
        "Y_train = pd.get_dummies(data['deceptive']).values\n",
        "\n",
        "nb_epoch = 1\n",
        "history = model.fit(indices, Y_train, validation_split=0.05,\n",
        "                    shuffle=True, batch_size=64, epochs=nb_epoch, verbose=1)   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9 samples, validate on 1 samples\n",
            "Epoch 1/1\n",
            "9/9 [==============================] - 16s 2s/step - loss: 0.6885 - acc: 0.5556 - val_loss: 0.4438 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hHGiSgzMDcwQ",
        "colab_type": "code",
        "outputId": "9404884b-7dfe-4901-a80c-b19a21be4401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 200, 200)          80000200  \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 200, 512)          935936    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 200, 512)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 512)               1574912   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 70)                35910     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 70)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 20)                1420      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 2)                 42        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 82,548,420\n",
            "Trainable params: 82,548,420\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NWSyRW76p1G_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_q = data['text'].values\n",
        "Y_train = pd.get_dummies(data['deceptive']).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v6yV-RSip1J3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_text = sentences_to_indices(X_train_q, word_to_index, 200) #X_train_q is list of sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bIu9a-c-qHAQ",
        "colab_type": "code",
        "outputId": "e3ad07ea-4bd3-4db7-8ff3-a18545b2571c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "nb_epoch = 1\n",
        "history = model.fit(X_train_text, Y_train, validation_split=0.05,\n",
        "                    shuffle=True, batch_size=64, epochs=nb_epoch, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1520 samples, validate on 80 samples\n",
            "Epoch 1/1\n",
            "1520/1520 [==============================] - 216s 142ms/step - loss: 0.4817 - acc: 0.7724 - val_loss: 0.5690 - val_acc: 0.7125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OBVo273CqLK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save_weights('dec_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CIkg2Bg9qO2a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv dec_model.h5 drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_hWZyLNtqURQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict([X_test], verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}